# -*- coding: utf-8 -*-
"""ВКР

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SqzisfeXNpLVxNgkBQziiH0nlkMS5oG9

# Подгатовка данных к анализу
"""

# Импортируем библиотеки
from google.colab import drive
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from scipy import stats
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score
from mlxtend.plotting import plot_decision_regions

drive.mount('/content/drive')
dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ВКР/citrus.csv')
dataset.head(10)

dataset.info()

dataset.isnull().sum()

dataset['name'].unique()

dataset['name'].value_counts()

"""# Предворительный анализ данных"""

dataset.describe()

plt.figure(figsize=(18, 10))

for idx, column in enumerate(dataset.columns[1:]):
    plt.subplot(2, 3, idx + 1)
    sns.boxplot(x=dataset[column])
    plt.title(f'Boxplot of {column}')

plt.tight_layout()
plt.show()

def remove_outliers(dataframe, feature, condition_feature, _name):

    feature_fraud = dataframe[feature].loc[dataframe[condition_feature] == _name].values
    Q1, Q3 = np.percentile(feature_fraud, [25, 75])
    IQR = Q3 - Q1
    low_boundary, high_boundary = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR
    outliers = [x for x in feature_fraud if x < low_boundary or x > high_boundary]
    dataframe_without_outliers = dataframe.drop(dataframe[(dataframe[feature] > high_boundary) | (dataframe[feature] < low_boundary)].index)

    return dataframe_without_outliers, len(outliers)
features = ['diameter', 'red', 'green', 'blue']
for feature in features:
  new_df_1, outlier_count = remove_outliers(dataset, feature, 'name', 'grapefruit')
  print('Количество выбросов: {}'.format(outlier_count), feature)
  new_df_2, outlier_count = remove_outliers(new_df_1, feature, 'name', 'orange')
  print('Количество выбросов: {}'.format(outlier_count), feature, '\n')

f, ax = plt.subplots(4, 3, figsize=(15,30))
colors = ['#B3F9C5', '#f9c5b3']

i = 0
for col in features:
    if i >= 4:
        break
    sns.boxplot(y=dataset[col], ax=ax[i, 0])
    ax[i, 0].set_title(f'Boxplot {col} до удаления выбросов')

    sns.boxplot(y=new_df_1[col], ax=ax[i, 1])
    ax[i, 1].set_title(f'Boxplot {col} после удаления выбросов')

    sns.boxplot(y=new_df_2[col], ax=ax[i, 2])
    ax[i, 2].set_title(f'Boxplot {col} после удаления выбросов')
    i += 1

plt.tight_layout()
plt.show()

plt.figure(figsize=(18, 10))

for idx, column in enumerate(new_df_2.columns[1:]):
    plt.subplot(2, 3, idx + 1)
    sns.boxplot(x=new_df_2[column])
    plt.title(f'Boxplot of {column}')

plt.tight_layout()
plt.show()

plt.figure(figsize=(18, 10))

for idx, column in enumerate(new_df_2.columns[1:]):
    plt.subplot(2, 3, idx + 1)
    sns.histplot(dataset[column], kde=True)
    plt.title(f'Histogram of {column}')

plt.tight_layout()
plt.show()

alpha = 0.05

for column in new_df_2.columns[1:]:
    # Тест Шапиро-Уилка
    shapiro_test = stats.shapiro(new_df_2[column])
    print(f'Tест Шапиро-Уилка: статистика = {shapiro_test.statistic}, p-значение = {shapiro_test.pvalue}')

    # Проверка гипотезы
    if shapiro_test.pvalue > alpha:
        print('Данные нормально распределены.')
    else:
        print('Данные не нормально распределены.')
    print()

name = {'orange': 0, 'grapefruit': 1}
new_df_2['name'] = new_df_2['name'].map(name)

new_df_2.head()

plt.figure(figsize=(10, 8))
correlation_matrix = new_df_2.corr(method='spearman')
sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', square=True, cbar_kws={"shrink": .8})
plt.title('Корреляционная матрица')
plt.show()

X = new_df_2.drop(['name', 'diameter'], axis=1)
y = new_df_2['name']
print(f'X shape: {X.shape} | y shape: {y.shape} ')

scaler = MinMaxScaler()
X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)

X.head()

"""

## Train Test разделение

Разделяем наш набор данных на обучающий (train) и тестовый (test) с помощью train_test_split(), мы берем 80% данных для обучения нашей модели и 20% оставляем в качестве проверочного набора данных:"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=15, stratify=y)

stats.ttest_ind (a=y_train, b=y_test)

"""## Обучение и выбор оптимальной модели

Далее попробуем следующие алгоритмы:

Logistic Regression (LR) </br>
Linear Discriminant Analysis (LDA)</br>
K-Nearest Neighbors (KNN)</br>
Classification and Regression Trees (CART)</br>
Gaussian Naive Bayes (NB)</br>
Support Vector Machines (SVM)</br>
"""

# создаем лист для тех моделей, которые будем изучать
models = []
models.append(('LR', LogisticRegression(solver='lbfgs', max_iter=1000)))
models.append(('LDA', LinearDiscriminantAnalysis()))
models.append(('KNN', KNeighborsClassifier()))
models.append(('CART', DecisionTreeClassifier()))
models.append(('NB', GaussianNB()))
models.append(('SVM', SVC(gamma='auto')))

# оцениваем их метрики
results = []
model_names = []
for name, model in models:
  kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)
  cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')
  results.append(cv_results)
  model_names.append(name)
  print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))

"""# Logistic Regression (LR) показали лучшие метрики среди всех алгоритмов.

## Обучение конкретной модели

"""

sk_lr = LogisticRegression(max_iter=10000)

# Обучаем модель на тренировочных данных
sk_lr.fit(X_train, y_train)

# Делаем предсказания на тестовых данных
sk_lr_pred_res = sk_lr.predict(X_test)

sk_lr_accuracy = accuracy_score(y_test, sk_lr_pred_res)

print(f'sk LR accuracy: {sk_lr_accuracy}')
print(f'sk LR prediction: {sk_lr_pred_res}')

"""## Визуализация решения"""

from sklearn.metrics import confusion_matrix
conf_matrix = confusion_matrix(y_test, sk_lr_pred_res)

plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Предсказанные')
plt.ylabel('Настоящие')
plt.title('Confusion Matrix')

plt.show()

from sklearn import model_selection, preprocessing, feature_selection, ensemble, linear_model, metrics, decomposition

## Accuray e AUC
'''
Теперь смотрим метрики.
НА ТЕСТОВОМ ДАТАСЕТЕ
'''
accuracy = metrics.accuracy_score(y_test, sk_lr_pred_res)#Оценим точность классификации.

'''
Получим результат
'''

## Precision e Recall
recall = metrics.recall_score(y_test, sk_lr_pred_res, average="weighted")
precision = metrics.precision_score(y_test, sk_lr_pred_res, average="weighted")
print("Recall (all 1s predicted right):", round(recall,2))
print("Precision (confidence when predicting a 1):", round(precision,2))
print("Detail:")
print(metrics.classification_report(y_test, sk_lr_pred_res, target_names=[str(i) for i in np.unique(y_test)]))

y_s = y_train
X_2d= X_train[['weight',	'green']].values

y_2d = y_s.values


sk_lr1 = LogisticRegression(solver='lbfgs', max_iter=10000, multi_class='auto')
sk_lr1.fit(X_2d, y_2d)

plt.title('LR surface with original features')
plot_decision_regions(X=X_2d, y=y_2d, clf=sk_lr1)

Xs = new_df_2[['weight',	'green']]
ys = new_df_2["name"].values

# Логистическая регрессия с преобразованными признаками
sk_lr2 = LogisticRegression(solver='lbfgs', max_iter=10000, multi_class='auto')
sk_lr2.fit(Xs, ys)

# Разделение данных на обучающую и тестовую выборки
X1_lr_train, X1_lr_test, y1_train, y1_test = train_test_split(Xs, ys, random_state=0)

sk_lr2.fit(X1_lr_train, y1_train)

plt.figure()
plt.title('Logistic Regression surface with transformed features')
plot_decision_regions(X=Xs.values, y=ys, clf=sk_lr2)
plt.show()

predicted = sk_lr2.predict(X1_lr_test)

## Accuray e AUC
'''
Теперь смотрим метрики.
НА ТЕСТОВОМ ДАТАСЕТЕ
'''
accuracy = metrics.accuracy_score(y1_test, predicted)#Оценим точность классификации.

'''
Получим результат
'''

## Precision e Recall
recall = metrics.recall_score(y1_test, predicted, average="weighted")
precision = metrics.precision_score(y1_test, predicted, average="weighted")
print("Recall (all 1s predicted right):", round(recall,2))
print("Precision (confidence when predicting a 1):", round(precision,2))
print("Detail:")
print(metrics.classification_report(y1_test, predicted, target_names=[str(i) for i in np.unique(y_test)]))